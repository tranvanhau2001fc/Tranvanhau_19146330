{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRAINCAMXUC_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVildiDLR2TV"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.utils                  import np_utils\n",
        "from keras.models                 import Sequential\n",
        "from keras.layers                 import Dense, Activation, BatchNormalization, Dropout, LSTM\n",
        "from keras.layers                 import Conv2D\n",
        "from keras.layers                 import MaxPooling2D\n",
        "from keras.layers                 import Flatten\n",
        "from keras.callbacks              import EarlyStopping \n",
        "from tensorflow.keras.optimizers  import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.image             import imread"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFpbju3ASsON",
        "outputId": "0d1ccf2e-e726-45c8-a1f4-da8985ddf654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################################################################\n",
        "from keras import datasets, Sequential\n",
        "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing import  image\n",
        "from keras.preprocessing.image import load_img, img_to_array,array_to_img,ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2 as cv"
      ],
      "metadata": {
        "id": "ItNP9KaUQPru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################################################################\n",
        "danhsach = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
        "dir_train = '/content/drive/MyDrive/Project_AI_final/cam_xuc/train' \n",
        "distpath = []\n",
        "y_train = []\n",
        "x_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "# Tạo dữ liệu\n",
        "def create_data(dir, x_train, y_train):\n",
        "  for i in danhsach:\n",
        "    path = os.path.join(dir,i)\n",
        "    index_label = danhsach.index(i)\n",
        "    for j in os.listdir(path):\n",
        "      img_path = os.path.join(path, j)\n",
        "      img = image.load_img(img_path, target_size=(200,200)) # độ phân giải tùy ae chọn nhé!\n",
        "      img = img_to_array(img)\n",
        "      img = img.reshape(200,200,3) #hàm reshape phải có cùng độ phân giải với target_size của nhé\n",
        "      img = img.astype('float32')\n",
        "      img = img/255\n",
        "      x_train.append(img)\n",
        "      y_train.append(index_label)\n",
        "create_data(dir_train, x_train, y_train) #tạo dữ liệu \n",
        "# xử lí dữ liệu\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "print(x_train.shape) # nhớ chú ý kích thước hình ảnh để tí cho vào input của model\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYcQxtAjZQid",
        "outputId": "7b0c8859-d5f4-4cc8-b535-b37a70eb43d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9937, 200, 200, 3)\n",
            "(9937, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "# Block 1/3\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3))) # 32 lần sử dụng bộ lọc, bộ lọc có kích thước là 3x3  \n",
        "# khai báo bộ lọc kernel và padding là same nghĩa là ảnh trước khi lọc và sau khi lọc phải cùng kích thước\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "##################################################\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) # Dense là full-connected, nối đầy đủ tế bào lại vs nhau\n",
        "model.add(Dense(7, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "Q5KQRBMpe_Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt=SGD(learning_rate=0.01,momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
        "history = model.fit(x_train,y_train,epochs = 40)\n"
      ],
      "metadata": {
        "id": "vcXexrM0fOFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d13c0f2-4e30-4dc0-e025-89f1b909c92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "311/311 [==============================] - 259s 830ms/step - loss: 0.4120 - accuracy: 0.3292\n",
            "Epoch 2/40\n",
            "311/311 [==============================] - 262s 843ms/step - loss: 0.3343 - accuracy: 0.4272\n",
            "Epoch 3/40\n",
            "311/311 [==============================] - 260s 835ms/step - loss: 0.3179 - accuracy: 0.4654\n",
            "Epoch 4/40\n",
            "311/311 [==============================] - 258s 831ms/step - loss: 0.3017 - accuracy: 0.4979\n",
            "Epoch 5/40\n",
            "311/311 [==============================] - 259s 833ms/step - loss: 0.2855 - accuracy: 0.5436\n",
            "Epoch 6/40\n",
            "311/311 [==============================] - 260s 835ms/step - loss: 0.2694 - accuracy: 0.5728\n",
            "Epoch 7/40\n",
            "311/311 [==============================] - 259s 834ms/step - loss: 0.2516 - accuracy: 0.6153\n",
            "Epoch 8/40\n",
            "311/311 [==============================] - 258s 830ms/step - loss: 0.2323 - accuracy: 0.6562\n",
            "Epoch 9/40\n",
            "311/311 [==============================] - 259s 833ms/step - loss: 0.2154 - accuracy: 0.6872\n",
            "Epoch 10/40\n",
            "311/311 [==============================] - 259s 834ms/step - loss: 0.1939 - accuracy: 0.7321\n",
            "Epoch 11/40\n",
            "311/311 [==============================] - 257s 827ms/step - loss: 0.1739 - accuracy: 0.7718\n",
            "Epoch 12/40\n",
            "311/311 [==============================] - 261s 838ms/step - loss: 0.1541 - accuracy: 0.8027\n",
            "Epoch 13/40\n",
            "311/311 [==============================] - 260s 835ms/step - loss: 0.1322 - accuracy: 0.8437\n",
            "Epoch 14/40\n",
            "311/311 [==============================] - 260s 835ms/step - loss: 0.1114 - accuracy: 0.8862\n",
            "Epoch 15/40\n",
            "311/311 [==============================] - 257s 828ms/step - loss: 0.0912 - accuracy: 0.9150\n",
            "Epoch 16/40\n",
            "311/311 [==============================] - 260s 835ms/step - loss: 0.0762 - accuracy: 0.9348\n",
            "Epoch 17/40\n",
            "311/311 [==============================] - 258s 829ms/step - loss: 0.0601 - accuracy: 0.9622\n",
            "Epoch 18/40\n",
            "311/311 [==============================] - 260s 835ms/step - loss: 0.0476 - accuracy: 0.9728\n",
            "Epoch 19/40\n",
            "311/311 [==============================] - 260s 835ms/step - loss: 0.0369 - accuracy: 0.9842\n",
            "Epoch 20/40\n",
            "311/311 [==============================] - 258s 830ms/step - loss: 0.0301 - accuracy: 0.9898\n",
            "Epoch 21/40\n",
            "311/311 [==============================] - 260s 834ms/step - loss: 0.0232 - accuracy: 0.9934\n",
            "Epoch 22/40\n",
            "311/311 [==============================] - 258s 831ms/step - loss: 0.0168 - accuracy: 0.9964\n",
            "Epoch 23/40\n",
            "311/311 [==============================] - 260s 835ms/step - loss: 0.0135 - accuracy: 0.9972\n",
            "Epoch 24/40\n",
            "311/311 [==============================] - 258s 830ms/step - loss: 0.0112 - accuracy: 0.9975\n",
            "Epoch 25/40\n",
            "311/311 [==============================] - 259s 832ms/step - loss: 0.0096 - accuracy: 0.9976\n",
            "Epoch 26/40\n",
            "311/311 [==============================] - 258s 831ms/step - loss: 0.0086 - accuracy: 0.9978\n",
            "Epoch 27/40\n",
            "311/311 [==============================] - 259s 834ms/step - loss: 0.0084 - accuracy: 0.9980\n",
            "Epoch 28/40\n",
            "311/311 [==============================] - 258s 830ms/step - loss: 0.0070 - accuracy: 0.9980\n",
            "Epoch 29/40\n",
            "311/311 [==============================] - 258s 831ms/step - loss: 0.0074 - accuracy: 0.9980\n",
            "Epoch 30/40\n",
            "311/311 [==============================] - 259s 834ms/step - loss: 0.0064 - accuracy: 0.9983\n",
            "Epoch 31/40\n",
            "311/311 [==============================] - 257s 828ms/step - loss: 0.0074 - accuracy: 0.9980\n",
            "Epoch 32/40\n",
            "311/311 [==============================] - 258s 831ms/step - loss: 0.0058 - accuracy: 0.9983\n",
            "Epoch 33/40\n",
            "311/311 [==============================] - 259s 831ms/step - loss: 0.0059 - accuracy: 0.9982\n",
            "Epoch 34/40\n",
            "311/311 [==============================] - 259s 834ms/step - loss: 0.0067 - accuracy: 0.9977\n",
            "Epoch 35/40\n",
            "311/311 [==============================] - 257s 828ms/step - loss: 0.0065 - accuracy: 0.9977\n",
            "Epoch 36/40\n",
            "311/311 [==============================] - 260s 837ms/step - loss: 0.0050 - accuracy: 0.9981\n",
            "Epoch 37/40\n",
            "311/311 [==============================] - 260s 836ms/step - loss: 0.0046 - accuracy: 0.9985\n",
            "Epoch 38/40\n",
            "311/311 [==============================] - 258s 831ms/step - loss: 0.0049 - accuracy: 0.9982\n",
            "Epoch 39/40\n",
            "311/311 [==============================] - 260s 834ms/step - loss: 0.0053 - accuracy: 0.9981\n",
            "Epoch 40/40\n",
            "311/311 [==============================] - 261s 838ms/step - loss: 0.0046 - accuracy: 0.9983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Project_AI_final/cam_xuc/camxuc.h5')"
      ],
      "metadata": {
        "id": "MvC5uuIeTfY-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}